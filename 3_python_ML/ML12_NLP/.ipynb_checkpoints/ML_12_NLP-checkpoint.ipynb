{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B00XpL1_u9Iq"
   },
   "source": [
    "### 這堂課目標\n",
    "<li>RNN處理文字內容</li>\n",
    "\n",
    "- Data cleaning (For English)\n",
    "\n",
    "- Word Tokenizer\n",
    "\n",
    "- Word embedding\n",
    "\n",
    "- dropout\n",
    "\n",
    "<li>中文怎麼辦？</li>\n",
    "\n",
    "- 斷詞\n",
    "\n",
    "\n",
    "<li>其他種類的文字相關深度學習模型</li>\n",
    "\n",
    "- Multi-input, multi-output\n",
    "\n",
    "- Other special types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                            Message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('spam_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning (For English)\n",
    "from [medium@datamonsters](https://medium.com/@datamonsters/text-preprocessing-in-python-steps-tools-and-examples-bf025f872908)\n",
    "\n",
    "- converting all letters to lower or upper case\n",
    "- converting numbers into words or removing numbers\n",
    "- removing punctuations, accent marks and other diacritics\n",
    "- removing white spaces\n",
    "- expanding abbreviations, stemming\n",
    "- removing stop words and particular words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = df.Message.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting all letters to lower\n",
    "text_data = [i.lower() for i in text_data]\n",
    "#removing numbers\n",
    "text_data = [re.sub(r'\\d+', '', i) for i in text_data]\n",
    "\n",
    "#removing punctuations, accent marks and other diacritics\n",
    "text_data = [re.sub(r'[!”#$%&’()*+,-./:;<=>?@[\\]^_`{|}~£]', '', i) for i in text_data]\n",
    "#no white spaces, so do not need to process\n",
    "#too many abbreviations to do, so just two example (abbreviation and stemming)\n",
    "text_data = [re.sub('comin', 'coming', i) for i in text_data]\n",
    "text_data = [re.sub(\"it's\", 'it is', i) for i in text_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stop word\n",
    "from sklearn.feature_extraction._stop_words import ENGLISH_STOP_WORDS\n",
    "# ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go',\n",
       " 'until',\n",
       " 'jurong',\n",
       " 'point',\n",
       " 'crazy',\n",
       " 'available',\n",
       " 'only',\n",
       " 'in',\n",
       " 'bugis',\n",
       " 'n',\n",
       " 'great',\n",
       " 'world',\n",
       " 'la',\n",
       " 'e',\n",
       " 'buffet',\n",
       " 'cine',\n",
       " 'there',\n",
       " 'got',\n",
       " 'amore',\n",
       " 'wat']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data = [i.split() for i in text_data]\n",
    "text_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove count: 37302\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['jurong',\n",
       " 'point',\n",
       " 'crazy',\n",
       " 'available',\n",
       " 'bugis',\n",
       " 'n',\n",
       " 'great',\n",
       " 'world',\n",
       " 'la',\n",
       " 'e',\n",
       " 'buffet',\n",
       " 'cine',\n",
       " 'got',\n",
       " 'amore',\n",
       " 'wat']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_count = 0\n",
    "for i in range(len(text_data)):\n",
    "    for j in text_data[i][:]:\n",
    "        if j in ENGLISH_STOP_WORDS:\n",
    "            text_data[i].remove(j)\n",
    "            remove_count+=1\n",
    "print('remove count:',remove_count)\n",
    "text_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "b\n",
      "b\n",
      "c\n",
      "d\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a', 'c', 'd']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##補充說明\n",
    "# test = ['a','b','b','c','d']\n",
    "# for i in test:\n",
    "#     print(i)\n",
    "#     if i =='b':\n",
    "#         test.remove(i)\n",
    "# test\n",
    "test = ['a','b','b','c','d']\n",
    "for i in test[:]:\n",
    "    print(i)\n",
    "    if i =='b':\n",
    "        test.remove(i)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_num = 5000\n",
    "token = keras.preprocessing.text.Tokenizer(num_words=max_num,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "token.fit_on_texts(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3844, 612, 574, 507, 1025, 29, 46, 227, 837, 68, 2542, 1026, 10, 3845, 57]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data = token.texts_to_sequences(text_data)\n",
    "text_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## (batch_size,timestep,feature)\n",
    "np.percentile((np.array([len(i) for i in text_data])),70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5572, 10), (5572, 1))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen = 10\n",
    "text_data = keras.preprocessing.sequence.pad_sequences(text_data, maxlen=maxlen)\n",
    "df.Category = df.Category.astype('category')\n",
    "target_data = df.Category.cat.codes\n",
    "target_data = np.array(target_data).reshape(-1,1)\n",
    "text_data.shape,target_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(text_data,target_data,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4457, 10), (4457, 1))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Embedding在幹嘛1](https://medium.com/royes-researchcraft/%E8%87%AA%E7%84%B6%E8%AA%9E%E8%A8%80%E8%99%95%E7%90%86-1-word-to-vector-%E5%AF%A6%E4%BD%9C%E6%95%99%E5%AD%B8-99b668faa296)\n",
    "#### [Embedding在幹嘛2](https://medium.com/life-of-small-data-engineer/%E8%83%BD%E8%A2%AB%E9%9B%BB%E8%85%A6%E7%90%86%E8%A7%A3%E7%9A%84%E6%96%87%E5%AD%97-nlp-%E4%B8%80-word-embedding-4146267019cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 64)          320000    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 418,945\n",
      "Trainable params: 418,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Embedding(max_num, 64))\n",
    "model.add(keras.layers.LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4457 samples, validate on 1115 samples\n",
      "Epoch 1/15\n",
      "4457/4457 [==============================] - 8s 2ms/sample - loss: 0.1985 - accuracy: 0.9316 - val_loss: 0.0889 - val_accuracy: 0.9713\n",
      "Epoch 2/15\n",
      "4457/4457 [==============================] - 6s 1ms/sample - loss: 0.0479 - accuracy: 0.9863 - val_loss: 0.0806 - val_accuracy: 0.9758\n",
      "Epoch 3/15\n",
      "4457/4457 [==============================] - 5s 1ms/sample - loss: 0.0213 - accuracy: 0.9942 - val_loss: 0.0867 - val_accuracy: 0.9731\n",
      "Epoch 4/15\n",
      "4457/4457 [==============================] - 4s 835us/sample - loss: 0.0131 - accuracy: 0.9960 - val_loss: 0.1044 - val_accuracy: 0.9758\n",
      "Epoch 5/15\n",
      "4457/4457 [==============================] - 5s 1ms/sample - loss: 0.0091 - accuracy: 0.9978 - val_loss: 0.1216 - val_accuracy: 0.9776\n",
      "Epoch 6/15\n",
      "4457/4457 [==============================] - 4s 964us/sample - loss: 0.0066 - accuracy: 0.9987 - val_loss: 0.0890 - val_accuracy: 0.9749\n",
      "Epoch 7/15\n",
      "4457/4457 [==============================] - 5s 1ms/sample - loss: 0.0055 - accuracy: 0.9989 - val_loss: 0.1039 - val_accuracy: 0.9794\n",
      "Epoch 8/15\n",
      "4457/4457 [==============================] - 5s 1ms/sample - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.1192 - val_accuracy: 0.9767\n",
      "Epoch 9/15\n",
      "4457/4457 [==============================] - 4s 837us/sample - loss: 0.0038 - accuracy: 0.9993 - val_loss: 0.1237 - val_accuracy: 0.9776\n",
      "Epoch 10/15\n",
      "4457/4457 [==============================] - 5s 1ms/sample - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.1178 - val_accuracy: 0.9704\n",
      "Epoch 11/15\n",
      "4457/4457 [==============================] - 4s 977us/sample - loss: 0.0072 - accuracy: 0.9987 - val_loss: 0.1142 - val_accuracy: 0.9776\n",
      "Epoch 12/15\n",
      "4457/4457 [==============================] - 4s 843us/sample - loss: 0.0044 - accuracy: 0.9993 - val_loss: 0.1254 - val_accuracy: 0.9776\n",
      "Epoch 13/15\n",
      "4457/4457 [==============================] - 4s 965us/sample - loss: 0.0036 - accuracy: 0.9993 - val_loss: 0.1233 - val_accuracy: 0.9722\n",
      "Epoch 14/15\n",
      "4457/4457 [==============================] - 4s 940us/sample - loss: 0.0032 - accuracy: 0.9993 - val_loss: 0.1230 - val_accuracy: 0.9713\n",
      "Epoch 15/15\n",
      "4457/4457 [==============================] - 4s 903us/sample - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.1085 - val_accuracy: 0.9731\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13d4a0550>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,epochs=15,validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 中文怎麼辦？\n",
    "- 斷詞：結巴斷詞、中研院斷詞\n",
    "- 沒有stemming的問題，但一樣有簡寫的問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 其他種類RNN相關深度學習模型\n",
    "- multi-input, multi-output (for non-text data):預測未來一週銷量\n",
    "\n",
    "- Seq2Seq (for text data):自動翻譯、文章摘要、回答問題、文章創作\n",
    "\n",
    "- image caption:照片轉文字敘述 （[附連結](https://milhidaka.github.io/chainer-image-caption/))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作業更改項目：交叉測試，紀錄測試集的RMSE值\n",
    "\n",
    "- stop word的影響：去除stop word, 沒去除stop word\n",
    "- 辭彙庫字數的影響：500,1000,5000 （假定embedding都固定為64）\n",
    "- Embedding數量的影響：16,32,64 （假定辭彙庫字數都固定為5000）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vocab_500</th>\n",
       "      <th>vocab_1000</th>\n",
       "      <th>vocab_5000</th>\n",
       "      <th>embedding_16</th>\n",
       "      <th>embedding_32</th>\n",
       "      <th>embedding_64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>去除stop word</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>沒去除stop word</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              vocab_500  vocab_1000  vocab_5000  embedding_16  embedding_32  \\\n",
       "去除stop word           0           0           0             0             0   \n",
       "沒去除stop word          0           0           0             0             0   \n",
       "\n",
       "              embedding_64  \n",
       "去除stop word              0  \n",
       "沒去除stop word             0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "row_index = ['去除stop word','沒去除stop word']\n",
    "column1_index = ['vocab_500', 'vocab_1000', 'vocab_5000', \n",
    "                 'embedding_16', 'embedding_32', 'embedding_64']\n",
    "pd.DataFrame(index=row_index, columns=column1_index, data=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "name": "ML_08_CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
